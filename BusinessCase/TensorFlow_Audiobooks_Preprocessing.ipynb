{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "-   Data: \n",
    "\n",
    "    - From an Audiobook App relates to the audio versions of books ONLY. \n",
    "    \n",
    "    - There are several variables: Customer ID, Book length overall (sum of the minute length of all purchases), Book length avg (average length in minutes of all purchases), Price paid_overall (sum of all purchases) ,Price Paid avg (average of all purchases), Review (a Boolean variable whether the customer left a review), Review out of 10 (if the customer left a review, his/her review out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number of support requests; everything from forgotten password to assistance for using the App), and Last visited minus purchase date (in days).\n",
    "\n",
    "    - The targets are a Boolean variable (0 or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s. \n",
    "\n",
    "\n",
    "-   Goal: \n",
    "\n",
    "    Create a machine learning algorithm based on our available data that can predict if a customer will buy again from the Audiobook company. Moreover, this model can identify the most important metrics for a customer to come back again. Identifying new customers creates value and growth opportunities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "raw_csv_data = pd.read_csv('Audiobooks_data.csv')\n",
    "\n",
    "# The inputs are all columns in the csv, except for the first one [:,0]\n",
    "# (which is just the arbitrary customer IDs that bear no useful information),\n",
    "# and the last one [:,-1] (which is our targets)\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data.iloc[:,1:-1]\n",
    "\n",
    "# The targets are in the last column. That's how datasets are conventionally organized.\n",
    "targets_all = raw_csv_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00994</th>\n",
       "      <th>1620</th>\n",
       "      <th>1620.1</th>\n",
       "      <th>19.73</th>\n",
       "      <th>19.73.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10.00</th>\n",
       "      <th>0.99</th>\n",
       "      <th>1603.80</th>\n",
       "      <th>5</th>\n",
       "      <th>92</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1143</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2882</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>680.4</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3342</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>475.2</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3416</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>4.61</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14078</th>\n",
       "      <td>28220</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>988.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14079</th>\n",
       "      <td>28671</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>313.2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>31134</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081</th>\n",
       "      <td>32832</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>615.6</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>251</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>3348</td>\n",
       "      <td>5.33</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14083 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00994    1620  1620.1  19.73  19.73.1  1  10.00  0.99  1603.80  5   92  \\\n",
       "0       1143  2160.0    2160   5.33     5.33  0   8.91  0.00      0.0  0    0   \n",
       "1       2059  2160.0    2160   5.33     5.33  0   8.91  0.00      0.0  0  388   \n",
       "2       2882  1620.0    1620   5.96     5.96  0   8.91  0.42    680.4  1  129   \n",
       "3       3342  2160.0    2160   5.33     5.33  0   8.91  0.22    475.2  0  361   \n",
       "4       3416  2160.0    2160   4.61     4.61  0   8.91  0.00      0.0  0    0   \n",
       "...      ...     ...     ...    ...      ... ..    ...   ...      ... ..  ...   \n",
       "14078  28220  1620.0    1620   5.33     5.33  1   9.00  0.61    988.2  0    4   \n",
       "14079  28671  1080.0    1080   6.55     6.55  1   6.00  0.29    313.2  0   29   \n",
       "14080  31134  2160.0    2160   6.14     6.14  0   8.91  0.00      0.0  0    0   \n",
       "14081  32832  1620.0    1620   5.33     5.33  1   8.00  0.38    615.6  0   90   \n",
       "14082    251  1674.0    3348   5.33    10.67  0   8.91  0.00      0.0  0    0   \n",
       "\n",
       "       0  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "...   ..  \n",
       "14078  0  \n",
       "14079  0  \n",
       "14080  0  \n",
       "14081  0  \n",
       "14082  1  \n",
       "\n",
       "[14083 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count how many targets are 1 \n",
    "num_one_targets = int(np.sum(targets_all))\n",
    "\n",
    "zero_targets_counter = 0\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "# Count the number of targets that are 0. \n",
    "# Once there are as many 0s as 1s, mark entries where the target is 0.\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "# Delete all indices in indices_to_remove.\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4474,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_equal_priors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4474, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_equal_priors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_inputs = scaler.fit_transform(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle inputs and targets together while preserving the pairing\n",
    "# shuffled_inputs, shuffled_targets = shuffle(scaled_inputs, targets_equal_priors, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787 3579 0.4993014808605756\n",
      "226 447 0.5055928411633109\n",
      "224 448 0.5\n"
     ]
    }
   ],
   "source": [
    "# Split into training (80%) and temporary (20%) sets\n",
    "train_inputs, temp_inputs, train_targets, temp_targets = train_test_split(\n",
    "    scaled_inputs, targets_equal_priors, test_size=0.2, random_state=42\n",
    ")\n",
    "# print(len(train_inputs), len(train_targets))\n",
    "# print(len(temp_inputs), len(temp_targets))\n",
    "\n",
    "# Split the temporary set into validation and test (50% each of the remaining 20%)\n",
    "validation_inputs, test_inputs, validation_targets, test_targets = train_test_split(\n",
    "    temp_inputs, temp_targets, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Check balancing\n",
    "print(np.sum(train_targets), len(train_targets), np.sum(train_targets) / len(train_targets))\n",
    "print(np.sum(validation_targets), len(validation_targets), np.sum(validation_targets) / len(validation_targets))\n",
    "print(np.sum(test_targets), len(test_targets), np.sum(test_targets) / len(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An .npz file is a simple way to combine multiple arrays into a single file. \n",
    "\n",
    ".npz files store multiple .npy files in a single compressed format.\n",
    "Internally, an .npz file is just a Zip file containing multiple .npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the three datasets in *.npz.\n",
    "\n",
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
